<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Post Effects # 1. Introduction & Background # Implement some posteffects you find interesting.
Convolution is a mathematical operation that combines two functions to produce a third function. In the context of image processing, convolution is used to apply a filter kernel to an image, which can be used to perform operations such as blurring, sharpening, edge detection, and more.
In p5.js, convolution can be implemented using shaders, which are programs that run on the GPU and can perform highly parallelized operations on images."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="Post Effects # 1. Introduction & Background # Implement some posteffects you find interesting.
Convolution is a mathematical operation that combines two functions to produce a third function. In the context of image processing, convolution is used to apply a filter kernel to an image, which can be used to perform operations such as blurring, sharpening, edge detection, and more.
In p5.js, convolution can be implemented using shaders, which are programs that run on the GPU and can perform highly parallelized operations on images."><meta property="og:type" content="article"><meta property="og:url" content="https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Post-Effects/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2023-06-19T16:57:03-05:00"><title>Post Effects | Visual Computing 2023-1 - G1 - DDC</title><link rel=manifest href=/showcase/manifest.json><link rel=icon href=/showcase/favicon.png type=image/x-icon><link rel=stylesheet href=/showcase/book.min.4b35fed0bea034bbc19c89c71e14b73fb9c68cfcc586b9382adfb9b7b103ba06.css integrity="sha256-SzX+0L6gNLvBnInHHhS3P7nGjPzFhrk4Kt+5t7EDugY=" crossorigin=anonymous><script defer src=/showcase/flexsearch.min.js></script>
<script defer src=/showcase/en.search.min.3a8d658c77eb93c7f12a2b8af49a700131e474f288eefb605d9fa61576dbe5a7.js integrity="sha256-Oo1ljHfrk8fxKiuK9JpwATHkdPKI7vtgXZ+mFXbb5ac=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/showcase/><span>Visual Computing 2023-1 - G1 - DDC</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Shortcodes</span><ul><li><a href=/showcase/docs/shortcodes/group-members/>Group Members</a></li><li><input type=checkbox id=section-6d6445ed16f829ce6720abb33c55105e class=toggle checked>
<label for=section-6d6445ed16f829ce6720abb33c55105e class="flex justify-between"><a href=/showcase/docs/shortcodes/shaders/>Shaders</a></label><ul><li><input type=checkbox id=section-2f065ccbcba70d5bdd25eb8a8f238142 class=toggle>
<label for=section-2f065ccbcba70d5bdd25eb8a8f238142 class="flex justify-between"><a role=button>Coloring</a></label><ul><li><a href=/showcase/docs/shortcodes/shaders/Coloring/Brightness-Coloring/>Brightness Coloring</a></li><li><a href=/showcase/docs/shortcodes/shaders/Coloring/Normal-Coloring/>Normal Coloring</a></li></ul></li><li><a href=/showcase/docs/shortcodes/shaders/Image-Processing/>Image Processing</a></li><li><a href=/showcase/docs/shortcodes/shaders/Photomosaic/>Photomosaic</a></li><li><a href=/showcase/docs/shortcodes/shaders/Post-Effects/ class=active>Post Effects</a></li><li><a href=/showcase/docs/shortcodes/shaders/Procedural-Texturing/>Procedural Texturing</a></li><li><a href=/showcase/docs/shortcodes/shaders/Space-Transformations-Spot-Light/>Space Transformations Spot Light</a></li><li><a href=/showcase/docs/shortcodes/shaders/Spatial-Coherence/>Spatial Coherence</a></li><li><a href=/showcase/docs/shortcodes/shaders/Texturing/>Texturing</a></li></ul></li><li><input type=checkbox id=section-67f2b433a931c89e2e9c26b761fd42ff class=toggle>
<label for=section-67f2b433a931c89e2e9c26b761fd42ff class="flex justify-between"><a href=/showcase/docs/shortcodes/visual-illusions/>Visual Illusions</a></label><ul><li><a href=/showcase/docs/shortcodes/visual-illusions/Academic-Report-3D-terrain-generation-with-perlin-noise/>Academic Report 3 D Terrain Generation With Perlin Noise</a></li><li><a href=/showcase/docs/shortcodes/visual-illusions/Academic-Report-Color-Average/>Academic Report Color Average</a></li><li><a href=/showcase/docs/shortcodes/visual-illusions/Academic-Report-Color-Blind/>Academic Report Color Blind</a></li><li><a href=/showcase/docs/shortcodes/visual-illusions/Academic-Report-Moir%C3%A9-Patterns/>Academic Report Moiré Patterns</a></li><li><a href=/showcase/docs/shortcodes/visual-illusions/Academic-Report-Spatial-Coherence/>Academic Report Spatial Coherence</a></li><li><a href=/showcase/docs/shortcodes/visual-illusions/Presentation-Video/>Presentation Video</a></li></ul></li></ul></li></ul><ul><li><a href=/showcase/posts/>Blog</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/showcase/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Post Effects</strong>
<label for=toc-control><img src=/showcase/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#post-effects>Post Effects</a><ul><li><a href=#1-introduction--background>1. Introduction & Background</a></li><li><a href=#2-code--results>2. Code & results</a></li><li><a href=#3-conclusion>3. Conclusion</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=post-effects>Post Effects
<a class=anchor href=#post-effects>#</a></h1><h2 id=1-introduction--background>1. Introduction & Background
<a class=anchor href=#1-introduction--background>#</a></h2><p>Implement some posteffects you find interesting.</p><p>Convolution is a mathematical operation that combines two functions to produce a third function. In the context of image processing, convolution is used to apply a filter kernel to an image, which can be used to perform operations such as blurring, sharpening, edge detection, and more.</p><p>In p5.js, convolution can be implemented using shaders, which are programs that run on the GPU and can perform highly parallelized operations on images. A typical convolution shader consists of a vertex shader and a fragment shader.</p><p>The vertex shader is responsible for transforming the input texture coordinates into output vertex positions. This shader is typically very simple and may not need to be modified for different convolution effects.</p><p>The fragment shader is where the convolution operation is performed. This shader takes in the input image texture, a filter kernel, and the texture coordinates of the current pixel, and outputs the convolved pixel value.</p><p>The fragment shader typically works by iterating over each pixel in the image and applying the convolution kernel to the surrounding pixels. The result of this convolution is a weighted sum of the input pixel values, where each weight is determined by the corresponding value in the kernel.</p><h2 id=2-code--results>2. Code & results
<a class=anchor href=#2-code--results>#</a></h2><ul><li>Blur.js</li></ul><p>In the preload() function, we load the image to apply the effect to the shader. In the setup() function, we create a canvas and set it to use WebGL. In the draw() function, we set the shader and set the necessary uniforms.</p><ul><li>convolution.vert</li></ul><p>“precision highp float;” : This line sets the precision for floating-point calculations in the shader. highp stands for high precision, and it ensures that the calculations are performed with maximum accuracy.</p><p>“attribute vec3 aPosition;”: This line declares a variable named aPosition, which is an attribute that represents the position of each vertex in the mesh.</p><p>“attribute vec2 aTexCoord;” : This line declares a variable named aTexCoord, which is an attribute that represents the texture coordinate for each vertex in the mesh.</p><p>“varying vec2 vTexCoord;” : This line declares a variable named vTexCoord, which is a varying variable that will be passed to the fragment shader. It represents the texture coordinate for the current fragment.</p><p>The main() function is where the vertex shader does its work. Here&rsquo;s what it does:</p><p>“vTexCoord = vec2(aTexCoord.x, 1.0 - aTexCoord.y);” : This line sets the value of vTexCoord to the same value as aTexCoord, but with the y coordinate flipped. This is because the texture coordinates in p5.js have the origin in the upper-left corner, while in OpenGL/WebGL they have the origin in the lower-left corner. Flipping the y coordinate ensures that the texture is sampled correctly.</p><p>“gl_Position = vec4(aPosition, 1.0);”: This line sets the position of the vertex in screen coordinates. It creates a vec4 with the x, y, and z coordinates of aPosition, and a w coordinate of 1.0. This is necessary because OpenGL/WebGL requires homogeneous coordinates for vertices.</p><ul><li>convolution.frag</li></ul><p>“precision highp float;”: This line sets the floating-point precision of the shader to high.</p><p>“uniform sampler2D tex0;”: This line defines a uniform variable tex0 of type sampler2D, which is a 2D texture. This texture is the input image.</p><p>“uniform vec2 texelSize;”: This line defines a uniform variable texelSize of type vec2, which represents the size of a single texel (texture element) in the input image.</p><p>“uniform float kernel[9];”: This line defines a uniform variable kernel of type float array with a length of 9. This array represents the convolution kernel which will be used to blur the input image.</p><p>“uniform float kernelWeight;”: This line defines a uniform variable kernelWeight of type float, which represents the sum of all the elements in the convolution kernel.</p><p>“varying vec2 vTexCoord;”: This line defines a varying variable vTexCoord of type vec2, which will hold the texture coordinates for the current fragment.</p><p>void main() {: This line starts the main function of the fragment shader.</p><p>“vec2 texCoord = vec2(1.0 - vTexCoord.x, vTexCoord.y);”: This line creates a new variable texCoord of type vec2, which represents the flipped x-coordinate texture coordinates.</p><p>“vec4 sum = vec4(0.0);”: This line creates a new variable sum of type vec4, which will be used to store the weighted sum of the convolution kernel applied to the input image.</p><p>The next 9 lines are where the convolution is performed. Each line calculates the weighted sum of the convolution kernel applied to a specific pixel in the input image. The texture2D function is used to sample the input image at a specific texture coordinate, and the corresponding element of the convolution kernel is multiplied by the sampled color. This process is repeated for 9 pixels surrounding the current pixel.</p><p>“gl_FragColor = sum / kernelWeight;”: This line sets the output color of the fragment to the weighted sum of the convolution kernel, normalized by the kernel weight. The resulting color is written to the output buffer.</p><ul><li>Image.jpg:</li></ul><p><img src=https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhwbZUdYl4zCLAYtj9-00J249sLD7DYQi0JDq0B6eHlxrWVxXUSvB-7AjJ5vEth2zYi6gNZxc2vkNh4qf0qTSNcTr3IkCx21uYSygnKyGAg-aGtsaxiM3OQ-8z39NN8oBWD8zKPndAI23BAVOar4Oss1lzbE3_vnGuIp4LZeFRSc6Wp8H9W5k_quC6smoc/s320/Aspose.Words.1b5bab1f-6071-49b8-80e4-36b65e7a4849.001.jpeg alt></p><ul><li>Image.jpg with the convolution(Blur) postEffect</li></ul><p><img src=https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiYVpDKSIzcUuVT2c0iOeFmZ0JW8jX_K0pg-B_R4npT2TB55kVypkD0wri-VenQNasJy7m3QfZGaiAn3nWoA1tD3QogZvmD6jPJiXD6ZpwolYR9fql1SPYhxdnwj2vSLeE3o0Zh6Dqp9IpayjgQ2UyOdseHMJbvNCEkBN5lmidPULn-dBeZtI3yyrsoe8/s320/Aspose.Words.1b5bab1f-6071-49b8-80e4-36b65e7a4849.002.png alt></p><h2 id=3-conclusion>3. Conclusion
<a class=anchor href=#3-conclusion>#</a></h2><p>The implementation of post-effects using convolution shaders in p5.js offers a powerful way to manipulate and enhance images in real-time. Convolution, a mathematical operation combining functions, is leveraged to apply various effects such as blurring, sharpening, and edge detection. The convolution operation is performed within a fragment shader, which runs on the GPU and can handle parallelized operations efficiently. The fragment shader iterates over each pixel in the image, applying a convolution kernel to calculate a weighted sum of surrounding pixel values. This process results in a new convolved pixel value. The vertex shader, responsible for transforming input texture coordinates to output vertex positions, typically requires minimal modification for different convolution effects.</p><p>By understanding and leveraging shaders, developers can explore a wide range of post-effects and creative image manipulations. Convolution shaders offer a flexible and efficient approach to achieve visually appealing results. The ability to perform these operations in real-time using p5.js and WebGL opens up new possibilities for interactive graphics and visual experiences on the web. Further experimentation and exploration of convolution and other shader-based techniques can lead to exciting and innovative visual effects in web-based applications.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/visualcomputing/showcase/commit/29a079f70a161bea2e0cbcab3ed314fb749e415c title='Last modified by Daniel991104 | June 19, 2023' target=_blank rel=noopener><img src=/showcase/svg/calendar.svg class=book-icon alt=Calendar>
<span>June 19, 2023</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#post-effects>Post Effects</a><ul><li><a href=#1-introduction--background>1. Introduction & Background</a></li><li><a href=#2-code--results>2. Code & results</a></li><li><a href=#3-conclusion>3. Conclusion</a></li></ul></li></ul></nav></div></aside></main></body></html>