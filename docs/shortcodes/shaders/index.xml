<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visual Computing 2023-1 - G1 - DDC</title><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/</link><description>Recent content on Visual Computing 2023-1 - G1 - DDC</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Image-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Image-Processing/</guid><description>Image Processing # 1. Introduction &amp;amp; Background # Digital image processing is the use of a digital computer to process digital images through an algorithm (Atalla &amp;amp; Kahng, n.d.). In webgl (i.e., GLSL ES) texturing is used to implement image processing (Charalambos, 2023).
For this exercise, different effects were applied to an image and a video. Using image processing through texturing, and implementing convolutions to apply different masks or kernels.</description></item><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Photomosaic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Photomosaic/</guid><description>Phptomosaic # 1. Introduction &amp;amp; Background # Photomosaic is a technique in visual computing that involves creating a larger image by assembling numerous smaller images called tiles. These tiles, often small photographs or images, are carefully chosen to replicate the colors and patterns of specific regions within the larger target image. When viewed from a distance, the tiles blend together to form a cohesive and visually appealing composition. Photomosaic has gained popularity as a creative and artistic way to transform images into stunning collages and visual representations.</description></item><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Post-Effects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Post-Effects/</guid><description>Post Effects # 1. Introduction &amp;amp; Background # Implement some posteffects you find interesting.
Convolution is a mathematical operation that combines two functions to produce a third function. In the context of image processing, convolution is used to apply a filter kernel to an image, which can be used to perform operations such as blurring, sharpening, edge detection, and more.
In p5.js, convolution can be implemented using shaders, which are programs that run on the GPU and can perform highly parallelized operations on images.</description></item><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Procedural-Texturing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Procedural-Texturing/</guid><description>Procedural Texturing # 1. Introduction &amp;amp; Background # The goal in procedural texturing is to procedurally generate a texture using an algorithm in such a way that the result can be mapped onto a shape as a texture. Procedural texturing requires the use of a frame buffer object which in p5.js is implemented as a p5.Graphics object (Procedural Texturing, 2023).
A framebuffer (frame buffer, or sometimes framestore) is a portion of random-access memory (RAM) containing a bitmap that drives a video display.</description></item><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Space-Transformations-Spot-Light/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Space-Transformations-Spot-Light/</guid><description>Space Transformations / Spot Light # 1. Introduction &amp;amp; Background # The implementation of a first-person spot light in creative mode allows for the creation of an interactive 3D scene with dynamic lighting effects. This code utilizes p5.js, a JavaScript library, to create a visually engaging experience. The scene consists of a rotating sphere placed against a galactic background. The lighting effect on the sphere is influenced by the position of the mouse, providing a dynamic and interactive element.</description></item><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Spatial-Coherence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Spatial-Coherence/</guid><description>Spatial Coherence # 1. Introduction &amp;amp; Background # Downsampling to convert an image to grayscale using shaders.
Technique: To convert an image to grayscale using shaders, we use downsampling. So, it reduces the resolution of the image by averaging multiple pixels into a single pixel, resulting in a lower resolution image. This technique applied in the following way to convert an image to grayscale using shaders:
First, the image is loaded into the shader program as a texture.</description></item><item><title/><link>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Texturing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://VisualComputingDDC.github.io/showcase/docs/shortcodes/shaders/Texturing/</guid><description>Texture Sampling # 1. Introduction &amp;amp; Background # A texture map is an image applied (mapped) to the surface of a shape or polygon. This may be a bitmap image or a procedural texture. They may be stored in common image file formats, referenced by 3d model formats or material definitions, and assembled into resource bundles (Texture Mapping, n.d.).
Texture sampling is the process of reading textures through the GPU.</description></item></channel></rss>